1. >Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.  
Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.  
Вы как инженер поддержки решили произвести данную операцию:  
-напишите список операций, которые вы будете производить для остановки запроса пользователя  
-предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB   


Я большую часть времени работал с ораклом. И там я четко знаю, что если мне нужно найти сессию, то я иду либо в OEM , либо обращаюсь к системной таблице v$session, 
ну а далее убить сессию, зная ее SID не проблема.
С монго я не работал, поэтому основываюсь только на теории.
Но судя по всему принцип такой же.
найти долгий запрос:

**db.currentOp()**   
```
db.adminCommand(
   {
     currentOp: true,
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : <db>
   }
)
```
  
у изнав  <opid> убить ее:  
**db.killOp()**  
`db.adminCommand( { "killOp": 1, "op": <opid> } )`  
  

В mongoDB можно настроить профилирование для отслеживания и диагностики медленных запросов.
Если мы включим профилирование для бд, то запросы будут записываться в коллекцию system.profile capped
например так можно включить профилирование:
`mongod --profile 1 --slowms 20`  
Ну а далее из журнала запросов уже можно выдергивать инфу:
`db.system.profile.find( {secs : { $gt : 180 } } ).sort( { ts: 1} );`  

Сложно сказать является ли проблемой то, что запрос выполняется более 3 мин, может быть это тяжелый отчет за большой период и мы укладываемся по времени.
Поэтому вариант с настройкой триггера, который бы отлавливал и убивал такие запросы я бы не рассматривал, а посмотрел бы в сторону мониторинга > настроил бы метрику,
которая оповещала меня в случае обнаружения запроса, который отрабатывает более ... минут.
А вот если наш долгий запрос является блокирующим для всех последующих, то это критично и тут уже можно и мониторинг придумать и какой нибудь алгоритм убивания этой сессии.
  
2. >Перед выполнением задания познакомьтесь с документацией по Redis latency troobleshooting.  
Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и увеличивается пропорционально количеству реплик сервиса.  
При масштабировании сервиса до N реплик вы увидели, что:  
-сначала рост отношения записанных значений к истекшим  
-Redis блокирует операции записи  
Как вы думаете, в чем может быть проблема?  

Была у меня на сопровождении одна система, которая взаимодейтвовала с редисом. У нас было 10 нод приклада и 5 серверов REDIS в кластере (сентинел).
В задании мы увеличиваем кол-во реплик сервиса, но не увеличиваем кол-во инстансов редиса, т.е. у нас не корректно настроена архитектура.
Думаю одна из причин наших проблем из задания в этом.
Redis однопоточный и все его команды являются атомарными. И получается пока команда запущена, никакая другая не может быть выполнена, т.е. редис не даст читать во время выполнения записи.



3. >Перед выполнением задания познакомьтесь с документацией по Common Mysql errors.  
Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:  
``InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '``  
-Как вы думаете, почему это начало происходить и как локализовать проблему?  
-Какие пути решения данной проблемы вы можете предложить?  
  

Если мы убедились, что вариант с перебоями в сети - это не наш случай, то проверяем:  
  
`show global variables like '%timeout';`  
  
Нас интересуют параметры которые отвечают за чтение, ну и за сброс коннекта, т.к. в ошибке мы увидели, что это селект..  
  
`connect_timeout` - Количество секунд ожидания до сброса коннекта.  
`net_read_timeout` - Количество секунд ожидания для получения дополнительных данных из соединения перед прекращением чтения. Когда сервер читает с клиента, `net_read_timeout` - это значение тайм-аута, определяющее, когда прерывать работу.  
Судя по рекомендациям мускула можно попробовать увеличить параметры `net_read_timeout, connect_timeout`  в 2 и более раз.  
  
Мускул конечно пишет еще про третий вариант устранения:  
Если не помогает предыдущий вариант, то проверяем значение `max_allowed_packet` - максимальный размер данных, которые могут быть переданы за один запрос. Правим в `/etv/my.cnf`.  
Но мне почему то кажется, что текст ошибки должен звучать иначе, не "потеря коннекта",  а что то вроде  "размер пакета превышен".  
  
Итог:   
   -проблема подключения к сети;  
   -огромное кол-во строк отправляются как часть одного или более запросов; Правим в глобальных переменных или конфиге и далее уже думаем, что будем делать с разросшимися данными в таблицах.  


4. >Перед выполнением задания ознакомтесь со статьей Common PostgreSQL errors из блога Percona.  
Вы решили перевезти гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.  
После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В `dmesg` вы видите, что:  
`postmaster invoked oom-killer`  
-Как вы думаете, что происходит?
-Как бы вы решили данную проблему?  
  
OOM - отличная функция, ибо пусть лучше будет убит процесс, чем ляжет система. Судя по статье, да и из названия функции понятно, что дело в нехватки памяти.  
Нужно искать какой процесс пожирает нашу память, либо править настройки.  
Linux может зарезервировать для процессов больше памяти, чем есть, но не выделять ее по факту, и этим поведением управляет параметр ядра Linux. За это отвечает переменная vm.overcommit_memory.  
Ядро не будет резервировать больше памяти, чем указано в параметре `overcommit_ratio`.  
  
`sysctl -a | grep overcommit`  
  
```
vm.nr_overcommit_hugepages = 0
vm.overcommit_kbytes = 0
vm.overcommit_memory = 2
vm.overcommit_ratio = 80
```

+ В принципе много статей, где пишут примерно одно и тоже:  "Чтобы не приходилось использовать OOM-Killer для завершения PostgreSQL, установите для `vm.overcommit_memory` значение 2.  
Это не гарантирует, что OOM-Killer не придется вмешиваться, но снизит вероятность принудительного завершения процесса PostgreSQL."  
Ну и тут статейка про оверкоммит, почему 2 выбрали  `https://www.kernel.org/doc/Documentation/vm/overcommit-accounting`  


